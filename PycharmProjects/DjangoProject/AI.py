import streamlit as st
import pandas as pd
import random
import spacy
from spacy.training import Example
from spacy.util import minibatch, compounding
import re
from pathlib import Path
import shutil
from difflib import SequenceMatcher
import io

# ===============================
# ğŸ“‚ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
# ===============================
MODEL_DIR = Path("models")
MODEL_DIR.mkdir(exist_ok=True)

# ===============================
# ğŸ“¦ ãƒ–ãƒ©ãƒ³ãƒ‰ä¸€è¦§å–å¾—é–¢æ•°
# ===============================
def get_brand_list():
    return [p.name for p in MODEL_DIR.iterdir() if (p / "product_code_model").exists()]

# ===============================
# âœ¨ ãƒ©ãƒ³ãƒ€ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆå“ç•ªå­¦ç¿’ç”¨ï¼‰
# ===============================
TEMPLATES = [
    "{} ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼ ãƒ¡ãƒ³ã‚º ãƒ¬ãƒ‡ã‚£ãƒ¼ã‚¹ äººæ°—ãƒ¢ãƒ‡ãƒ«",
    "NIKE {} AIR FORCE 1 ãƒŠã‚¤ã‚­ ã‚¨ã‚¢ãƒ•ã‚©ãƒ¼ã‚¹ ãƒ¯ãƒ³",
    "adidas {} ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¹ã‚¿ãƒ¼ ã‚¢ãƒ‡ã‚£ãƒ€ã‚¹ å®šç•ªãƒ¢ãƒ‡ãƒ«",
    "New Balance {} ãƒ‹ãƒ¥ãƒ¼ãƒãƒ©ãƒ³ã‚¹ ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º",
    "CONVERSE {} ã‚ªãƒ¼ãƒ«ã‚¹ã‚¿ãƒ¼ ã‚³ãƒ³ãƒãƒ¼ã‚¹ ãƒã‚¤ã‚«ãƒƒãƒˆ",
    "PUMA {} ãƒ—ãƒ¼ãƒ ã‚¹ãƒãƒ¼ãƒ„ã‚·ãƒ¥ãƒ¼ã‚º",
    "Reebok {} ãƒªãƒ¼ãƒœãƒƒã‚¯ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º",
    "THE NORTH FACE {} ãƒãƒ¼ã‚¹ãƒ•ã‚§ã‚¤ã‚¹ ã‚¸ãƒ£ã‚±ãƒƒãƒˆ ãƒ¡ãƒ³ã‚º",
    "UNIQLO {} ãƒ¦ãƒ‹ã‚¯ãƒ­ ã‚·ãƒ£ãƒ„ é•·è¢– ãƒ¡ãƒ³ã‚º",
    "GU {} ãƒ¬ãƒ‡ã‚£ãƒ¼ã‚¹ ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ æ˜¥ å¤ æ–°ä½œ",
    "{} Tã‚·ãƒ£ãƒ„ åŠè¢– ç¶¿100%",
    "{} ãƒãƒƒã‚° ãƒˆãƒ¼ãƒˆ ãƒ¬ãƒ‡ã‚£ãƒ¼ã‚¹ ãƒ–ãƒ©ãƒ³ãƒ‰ äººæ°—",
    "{} ã‚­ãƒ£ãƒƒãƒ— å¸½å­ ãƒ¡ãƒ³ã‚º ãƒ¬ãƒ‡ã‚£ãƒ¼ã‚¹",
    "å‹ç•ª {} ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼ é´ é€æ–™ç„¡æ–™",
    "å“ç•ª {} ãƒ‡ãƒ‹ãƒ  ãƒ‘ãƒ³ãƒ„ ã‚¸ãƒ¼ãƒ³ã‚º",
    "{} ãƒ™ãƒ«ãƒˆ ãƒ¡ãƒ³ã‚º ãƒ“ã‚¸ãƒã‚¹ æœ¬é©",
    "å•†å“ã‚³ãƒ¼ãƒ‰ {} ãƒªãƒ¥ãƒƒã‚¯ é€šå‹¤ é€šå­¦",
]

# ===============================
# ğŸ§  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
# ===============================
def create_training_data(codes, n_variants=10):
    data = []
    for code in codes:
        for _ in range(n_variants):
            template = random.choice(TEMPLATES)
            text = template.format(code)
            for match in re.finditer(re.escape(code), text):
                start, end = match.span()
                data.append((text, {"entities": [(start, end, "PRODUCT_CODE")]}))
    return data

# ===============================
# ğŸ§  ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# ===============================
def train_model_for_brand(codes, brand_name, continue_training=False):
    brand_path = MODEL_DIR / brand_name / "product_code_model"
    brand_path.parent.mkdir(exist_ok=True, parents=True)

    if continue_training and brand_path.exists():
        nlp = spacy.load(brand_path)
        ner = nlp.get_pipe("ner")
        st.info(f"âœ… {brand_name} ã®æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§è¿½åŠ å­¦ç¿’")
    else:
        try:
            nlp = spacy.blank("ja")
        except Exception:
            nlp = spacy.blank("xx")
        ner = nlp.add_pipe("ner")
        ner.add_label("PRODUCT_CODE")
        st.info(f"ğŸ†• {brand_name} ã®æ–°è¦ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ")

    optimizer = nlp.resume_training() if continue_training else nlp.initialize()
    train_data = create_training_data(codes)

    progress = st.progress(0)
    for epoch in range(5):
        random.shuffle(train_data)
        losses = {}
        batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.5))
        for batch in batches:
            examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in batch]
            nlp.update(examples, sgd=optimizer, losses=losses)
        st.write(f"Epoch {epoch+1} Losses: {losses}")
        progress.progress((epoch + 1) / 5)

    nlp.to_disk(brand_path)

    # å“ç•ªãƒªã‚¹ãƒˆä¿å­˜
    codes_file = brand_path / "codes.txt"
    with open(codes_file, "w", encoding="utf-8") as f:
        for code in codes:
            f.write(f"{code}\n")

    st.success(f"ğŸ‰ {brand_name} ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å®Œäº†ï¼")

    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å³æ™‚æ›´æ–°
    st.session_state.brands = get_brand_list()

# ===============================
# ğŸ” å“ç•ªæŠ½å‡ºï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰
# ===============================
def extract_codes_with_brand(text, brand_name, similarity_threshold=0.2):
    brand_path = MODEL_DIR / brand_name / "product_code_model"
    if not brand_path.exists():
        st.warning(f"âŒ {brand_name} ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return []

    nlp = spacy.load(brand_path)
    doc = nlp(text)

    codes_path = brand_path / "codes.txt"
    if codes_path.exists():
        with open(codes_path, "r", encoding="utf-8") as f:
            trained_codes = [line.strip() for line in f if line.strip()]
    else:
        trained_codes = []

    results = set()
    # NERæŠ½å‡ºçµæœï¼ˆ3æ–‡å­—ä»¥ä¸‹ã¯ç„¡è¦–ï¼‰
    for ent in doc.ents:
        if (
            ent.label_ == "PRODUCT_CODE"
            and re.fullmatch(r"[A-Za-z0-9]+", ent.text)
            and len(ent.text) > 3
        ):
            results.add(ent.text)

    # é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
    for match in re.findall(r"\b[A-Za-z0-9]+\b", text):
        if len(match) <= 3:
            continue
        for code in trained_codes:
            ratio = SequenceMatcher(None, match, code).ratio()
            if ratio >= similarity_threshold:
                results.add(match)

    return sorted(results)

# ===============================
# âš™ï¸ Streamlit UI
# ===============================
st.title("ğŸ§© ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ å“ç•ªæŠ½å‡ºAIï¼ˆExcelå¯¾å¿œï¼‰")
tab1, tab2, tab3 = st.tabs(["ğŸ“˜ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’", "ğŸ§  å“ç•ªæŠ½å‡º", "ğŸ§¹ ãƒ¢ãƒ‡ãƒ«ç®¡ç†"])

# ====== ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¿ãƒ– ======
with tab1:
    st.header("ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»å†å­¦ç¿’")
    uploaded = st.file_uploader("ğŸ“¤ å“ç•ªãƒªã‚¹ãƒˆExcelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆ—åã€å“ç•ªã€ï¼‰", type="xlsx", key="train")
    brand_name = st.text_input("ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’å…¥åŠ›", key="train_brand")
    if uploaded and brand_name.strip():
        try:
            df = pd.read_excel(uploaded)
        except Exception as e:
            st.error(f"âŒ Excel ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        else:
            if "å“ç•ª" not in df.columns:
                st.error("âŒ Excelã«ã€å“ç•ªã€åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                codes = df["å“ç•ª"].dropna().astype(str).unique().tolist()
                st.write(f"âœ… èª­ã¿è¾¼ã‚“ã å“ç•ªæ•°: {len(codes)}")
                st.dataframe(df.head())
                mode = st.radio("å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ", ["æ–°è¦å­¦ç¿’", "è¿½åŠ å­¦ç¿’"], horizontal=True)
                if st.button("ğŸš€ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹"):
                    train_model_for_brand(
                        codes, brand_name.strip(), continue_training=(mode=="è¿½åŠ å­¦ç¿’")
                    )
    else:
        st.info("ğŸ“‚ Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ====== å“ç•ªæŠ½å‡ºã‚¿ãƒ– ======
with tab2:
    st.header("Excel ã‹ã‚‰å•†å“ååˆ—ã‚’èª­ã¿è¾¼ã‚“ã§å“ç•ªæŠ½å‡º")
    uploaded_extract = st.file_uploader(
        "ğŸ“¤ Excel ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆ—åã€å•†å“åã€ï¼‰",
        type="xlsx",
        key="extract"
    )

    st.subheader("â‘¢ å“ç•ªæŠ½å‡º")

    # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
    if "brands" not in st.session_state:
        st.session_state.brands = get_brand_list()

    brand_name = st.selectbox(
        "æŠ½å‡ºã«ä½¿ã†ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’é¸æŠ",
        st.session_state.brands if st.session_state.brands else ["ãƒ¢ãƒ‡ãƒ«ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“"]
    )

    similarity_threshold = st.slider(
        "é¡ä¼¼åº¦é–¾å€¤ã‚’è¨­å®šï¼ˆ0ã«è¿‘ã„ã»ã©ã‚†ã‚‹ãæŠ½å‡ºï¼‰",
        0.0, 1.0, 0.2, 0.05
    )

    if uploaded_extract and brand_name and brand_name != "ãƒ¢ãƒ‡ãƒ«ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“":
        try:
            df_extract = pd.read_excel(uploaded_extract)
        except Exception as e:
            st.error(f"âŒ Excel ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        else:
            if "å•†å“å" not in df_extract.columns:
                st.error("âŒ Excelã«ã€å•†å“åã€åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                if st.button("ğŸ” æŠ½å‡ºå®Ÿè¡Œ"):
                    extracted_list = []
                    for text in df_extract["å•†å“å"]:
                        codes = extract_codes_with_brand(
                            str(text),
                            brand_name.strip(),
                            similarity_threshold
                        )
                        extracted_list.append(", ".join(codes))
                    df_extract["æŠ½å‡ºå“ç•ª"] = extracted_list
                    st.success(f"âœ… å“ç•ªæŠ½å‡ºå®Œäº†ï¼ é¡ä¼¼åº¦é–¾å€¤={similarity_threshold}")
                    st.dataframe(df_extract)

                    output = io.BytesIO()
                    df_extract.to_excel(output, index=False)
                    st.download_button(
                        "ğŸ’¾ æŠ½å‡ºçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=output.getvalue(),
                        file_name="æŠ½å‡ºçµæœ.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
    else:
        st.info("ğŸ“‚ Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

# ====== ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¿ãƒ– ======
if "brands" not in st.session_state:
    st.session_state.brands = get_brand_list()

with tab3:
    st.header("ãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥ãƒ¢ãƒ‡ãƒ«ç®¡ç†")
    st.write("ğŸ“¦ å­˜åœ¨ã™ã‚‹ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ä¸€è¦§:")
    st.write(", ".join(st.session_state.brands) if st.session_state.brands else "ï¼ˆã¾ã ã‚ã‚Šã¾ã›ã‚“ï¼‰")

    brand_name_manage = st.text_input("ç®¡ç†å¯¾è±¡ãƒ–ãƒ©ãƒ³ãƒ‰åã‚’å…¥åŠ›", key="manage_brand")
    if brand_name_manage.strip():
        brand_path = MODEL_DIR / brand_name_manage.strip() / "product_code_model"
        if brand_path.exists():
            st.success(f"âœ… {brand_name_manage.strip()} ã®ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã¾ã™")
            if st.button(f"ğŸ—‘ï¸ {brand_name_manage.strip()} ãƒ¢ãƒ‡ãƒ«å‰Šé™¤ï¼ˆåˆæœŸåŒ–ï¼‰", key="delete"):
                shutil.rmtree(brand_path.parent)
                st.warning("ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                st.session_state.brands = get_brand_list()
        else:
            st.info(f"â„¹ï¸ {brand_name_manage.strip()} ãƒ¢ãƒ‡ãƒ«ã¯ã¾ã å­˜åœ¨ã—ã¾ã›ã‚“")
